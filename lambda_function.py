# -*- coding: utf-8 -*-
"""lambda_function.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SDD_PR4A691Zw9sLhQK35lg2b35BeZYx
"""

# importing the modules
import json
import os 
import time
import datetime
import pymysql
import requests

# Load environment variables as defined in the cloudformation template. 
host= os.environ['HOST']
port= os.environ['PORT']
dbname = os.environ['DBNAME']
user = os.environ['USER']
password = os.environ['PASSWORD']
api_key = os.environ['APIKEY']
news_db_table = os.environ['NEWS_TABLE_NAME']

# Function to fetch news and update database with the results 
def update_news_into_db(event):
  a = eval(event["body"])
  news_query_from_date = a['from']
  news_topic = a['topic']
  PARAMS = {'q':news_topic,'from':news_query_from_date,'sortBy':'publishedAt','apiKey':api_key}
  r = requests.get(url = 'http://newsapi.org/v2/everything', params = PARAMS)     
  data = r.json() 
  conn = pymysql.connect(host, user=user,port=port,passwd=password, db=dbname)
  cursor = connection.cursor()
  sql = "INSERT INTO {} (`PublishedAtTimestamp`, `Title`, `Description`, `Url`, `Content`, `ImageUrl`) VALUES (%s, %s, %s, %s, %s, %s)".format(news_db_table)
  for i in data['articles']:
    string = i['publishedAt']
    year = int(string[0:4])
    month = int(string[5:7])
    day = int(string[8:10])
    hour = int(string[11:13])
    minutes = int(string[14:16])
    seconds = int(string[17:19])
    timestamp = int(datetime.datetime(year,month,day,hour,minutes,seconds).timestamp())
    title = i['title']
    description = i['description']
    url = i['url']
    image_url = i['urlToImage']
    content = i['content']
    cursor.execute(sql, (timestamp,title,description,url,content,image_url))
    connection.commit()
  return {'statusCode':200,'body':json.dumps('All records of have been updated in the database'),'headers': {'Access-Control-Allow-Origin': '*','Access-Control-Allow-Credentials': True}}

# Function to fetch results using the google api since for demo it will be better to use google api rather than directly  
# Just returning all the results using select *.Using the api from google documentation we can already see that it provides 
# filters based on what topic to be searched and from when in timestamp. 
# The values been inserted using above function in database can be queried using publishedAt timestamp and used for doing any further analysis based on requirements.
def fetch_results_from_api(event):
  results = {'result-data':[]}
  news_topic = a['topic']
  news_query_from_date = a['from']
  PARAMS = {'q':news_topic,'from':news_query_from_date,'sortBy':'publishedAt','apiKey':api_key}
  r = requests.get(url = 'http://newsapi.org/v2/everything', params = PARAMS)
  data = r.json()
  for i in data['articles']:
    date_of_release = i['publishedAt']
    title = i['title']
    description = i['description']
    url = i['url']
    image_url = i['urlToImage']
    content = i['content']
    results['result-data'].append({'date-of-release':date_of_release,'title':title,'description':description,'url':url,'image-url':image_url,'content':content})  
  return {'statusCode':200,'body':json.dumps(results),'headers': {'Access-Control-Allow-Origin': '*','Access-Control-Allow-Credentials': True}}

# main lambda function begins here
def lambda_handler(event, context):
    # GET request condition checkpoint 
    if event['resource']=="/resume" and event['httpMethod']=='GET':
      if event["queryStringParameters"]["function"]=="fetch-news-db": 
        return fetch_news_from_db(event)
    # POST request condition checkpoint    
    elif event['resource']=="/resume" and event['httpMethod']=='POST':
      if event['queryStringParameters']['function']=='update-news-db':
        return update_news_into_db(event)